{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import product\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(color_codes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_excel('beer-reviews.xlsx')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "                                              0.0/42.8 MB ? eta -:--:--\n",
      "                                              0.1/42.8 MB 3.3 MB/s eta 0:00:13\n",
      "                                              0.3/42.8 MB 4.2 MB/s eta 0:00:11\n",
      "                                              0.8/42.8 MB 6.0 MB/s eta 0:00:08\n",
      "     -                                        1.8/42.8 MB 10.5 MB/s eta 0:00:04\n",
      "     --                                       2.5/42.8 MB 12.5 MB/s eta 0:00:04\n",
      "     ----                                     4.6/42.8 MB 18.4 MB/s eta 0:00:03\n",
      "     -----                                    6.3/42.8 MB 22.5 MB/s eta 0:00:02\n",
      "     -------                                  8.3/42.8 MB 24.1 MB/s eta 0:00:02\n",
      "     ---------                               10.9/42.8 MB 38.5 MB/s eta 0:00:01\n",
      "     -----------                             12.9/42.8 MB 50.4 MB/s eta 0:00:01\n",
      "     -------------                           14.7/42.8 MB 50.4 MB/s eta 0:00:01\n",
      "     --------------                          16.4/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     -----------------                       18.7/42.8 MB 50.4 MB/s eta 0:00:01\n",
      "     ------------------                      20.4/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     --------------------                    22.6/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     ----------------------                  24.5/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     -----------------------                 26.2/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     -------------------------               28.2/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     ---------------------------             30.1/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     -----------------------------           32.1/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     ------------------------------          33.0/42.8 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------        35.4/42.8 MB 43.5 MB/s eta 0:00:01\n",
      "     ----------------------------------      37.7/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     ------------------------------------    39.8/42.8 MB 46.7 MB/s eta 0:00:01\n",
      "     -------------------------------------   41.2/42.8 MB 43.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.7/42.8 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.8/42.8 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.8/42.8 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.8/42.8 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.8/42.8 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.8/42.8 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  42.8/42.8 MB 40.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 42.8/42.8 MB 18.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.7.0,>=3.6.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.24.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rahul\\appdata\\roaming\\python\\python311\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     amazing stout expensive worth price\n",
       "1           beer meet exceeded unreal hype simply amazing\n",
       "2                   let sit warm room little unbelievable\n",
       "3       small pour ebony dark real head intense rich a...\n",
       "4       vintage 2022 served tap toppling goliath snuli...\n",
       "                              ...                        \n",
       "6626    poured bottle snifter home thanks darin share ...\n",
       "6627    good god man holy shit really good beer blesse...\n",
       "6628    appearance bubble show lifts head fullsome thr...\n",
       "6629    pours sure describe color golden yellow brown ...\n",
       "6630    tropical nose sweet like sunnyd nice acidity a...\n",
       "Name: body, Length: 6631, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_words = [word for word in filtered_words if word.isalnum()]\n",
    "    return \" \".join(filtered_words)\n",
    "df['body']=df['body'].str.lower()\n",
    "\n",
    "df['body'] = df['body'].astype(str).apply(remove_stopwords)\n",
    "df['body']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>body</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>amazing stout expensive worth price</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>beer meet exceeded unreal hype simply amazing</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>let sit warm room little unbelievable</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>small pour ebony dark real head intense rich a...</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>vintage 2022 served tap toppling goliath snuli...</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          item  \\\n",
       "0  Kentucky Brunch Brand Stout   \n",
       "1  Kentucky Brunch Brand Stout   \n",
       "2  Kentucky Brunch Brand Stout   \n",
       "3  Kentucky Brunch Brand Stout   \n",
       "4  Kentucky Brunch Brand Stout   \n",
       "\n",
       "                                                body  rating  \n",
       "0                amazing stout expensive worth price    5.00  \n",
       "1      beer meet exceeded unreal hype simply amazing    5.00  \n",
       "2              let sit warm room little unbelievable    5.00  \n",
       "3  small pour ebony dark real head intense rich a...    4.67  \n",
       "4  vintage 2022 served tap toppling goliath snuli...    5.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B\n",
    "Assume that a customer, who will be using this recommender system, has specified 3 attributes\n",
    "in a product. E.g., one website describes multiple attributes of beer (but you should choose attributes\n",
    "from the actual data)\n",
    "Perform a word frequency analysis of beer reviews is a better way\n",
    "to find important attributes in the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>beer</td>\n",
       "      <td>5266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>head</td>\n",
       "      <td>3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14880</th>\n",
       "      <td>taste</td>\n",
       "      <td>3483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8867</th>\n",
       "      <td>light</td>\n",
       "      <td>2891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8885</th>\n",
       "      <td>like</td>\n",
       "      <td>2537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>hoax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>hobbyists</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>hog</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>hogan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16812</th>\n",
       "      <td>zythos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16813 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  frequency\n",
       "1829        beer       5266\n",
       "7320        head       3650\n",
       "14880      taste       3483\n",
       "8867       light       2891\n",
       "8885        like       2537\n",
       "...          ...        ...\n",
       "7520        hoax          1\n",
       "7521   hobbyists          1\n",
       "7526         hog          1\n",
       "7527       hogan          1\n",
       "16812     zythos          1\n",
       "\n",
       "[16813 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate word frequencies using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['body'])\n",
    "\n",
    "# Calculate the frequency of each word in the reviews\n",
    "word_frequencies = pd.DataFrame({'word': vectorizer.get_feature_names_out(), 'frequency': np.array(X.sum(axis=0))[0]})\n",
    "word_frequencies=word_frequencies.sort_values(['frequency'],ascending=False)\n",
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beer_attributes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rahul\\OneDrive\\Documents\\Fall\\Unstructured data analytics\\Assignment 2\\beer-recommender-system\\assignment-sanj-rach.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m word_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(word_frequencies[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m attributes \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m word_list \u001b[39mif\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m beer_attributes]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(attributes)\n",
      "\u001b[1;32mc:\\Users\\rahul\\OneDrive\\Documents\\Fall\\Unstructured data analytics\\Assignment 2\\beer-recommender-system\\assignment-sanj-rach.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m word_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(word_frequencies[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m attributes \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m word_list \u001b[39mif\u001b[39;00m x \u001b[39min\u001b[39;00m beer_attributes]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(attributes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'beer_attributes' is not defined"
     ]
    }
   ],
   "source": [
    "word_list = list(word_frequencies['word'])\n",
    "attributes = [x for x in word_list if x in beer_attributes]\n",
    "print(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attributes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rahul\\OneDrive\\Documents\\Fall\\Unstructured data analytics\\Assignment 2\\beer-recommender-system\\assignment-sanj-rach.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m array_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mattribute\u001b[39m\u001b[39m'\u001b[39m: attributes})\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m attr_word_freq\u001b[39m=\u001b[39mword_frequencies\u001b[39m.\u001b[39mmerge(array_df,left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mattribute\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m attr_word_freq\u001b[39m=\u001b[39m attr_word_freq\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mattribute\u001b[39m\u001b[39m'\u001b[39m,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'attributes' is not defined"
     ]
    }
   ],
   "source": [
    "array_df = pd.DataFrame({'attribute': attributes})\n",
    "attr_word_freq=word_frequencies.merge(array_df,left_on='word', right_on='attribute')\n",
    "attr_word_freq= attr_word_freq.drop('attribute',axis=1)\n",
    "attr_word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task F\n",
    "\n",
    "How would your recommendation change if you use word vectors (e.g., the spaCy package with medium sized pretrained word vectors) instead of the plain vanilla bag-of-words cosine similarity? One way to analyze the difference would be to consider the % of reviews that mention a preferred attribute. E.g., if you recommend a product, what % of its reviews mention an attribute specified by the customer? Do you see any difference across bag-of-words and word vector approaches? Explain. This article may be useful: https://medium.com/swlh/word-embeddings-versus-bag-of-words-the-curious-case-of-recommender-systems-6ac1604d4424?source=friends_link&sk=d746da9f094d1222a35519387afc6338\n",
    "Note that the article doesn’t claim that bag-of-words will always be better than word embeddings for recommender systems. It lays out conditions under which it is likely to be the case. That is, depending on the attributes you use, you may or may not see the same effect. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "cust_attr= ['robust','fruity','hoppy']\n",
    "\n",
    "# Load spaCy with medium-sized pretrained word vectors\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Function to calculate word vector similarity\n",
    "def word_vector_similarity(df):\n",
    "    text1 = df['body']\n",
    "    text2 = df['Customer attribute']\n",
    "    doc1 = nlp(text1)\n",
    "    doc2 = nlp(text2)\n",
    "    return doc1.similarity(doc2)\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "def sentiment_analysis(df):\n",
    "    sentiment= sentiment_pipeline(df['body'])\n",
    "    if sentiment[0]['label']=='POSITIVE':\n",
    "        return sentiment[0]['score']\n",
    "    else:\n",
    "        return (-sentiment[0]['score'])\n",
    "\n",
    "df1= df.copy()\n",
    "df2= df.copy()\n",
    "df3=df.copy()\n",
    "\n",
    "df1['Customer attribute'] = cust_attr[0]\n",
    "df2['Customer attribute'] = cust_attr[1]\n",
    "df3['Customer attribute'] = cust_attr[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_20132\\1809566172.py:12: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return doc1.similarity(doc2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_20132\\1809566172.py:12: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return doc1.similarity(doc2)\n",
      "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_20132\\1809566172.py:12: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return doc1.similarity(doc2)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (580 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (580) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rahul\\OneDrive\\Documents\\Fall\\Unstructured data analytics\\Assignment 2\\beer-recommender-system\\assignment-sanj-rach.ipynb Cell 13\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df2[\u001b[39m'\u001b[39m\u001b[39mSimilarity Score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df2\u001b[39m.\u001b[39mapply(word_vector_similarity, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df3[\u001b[39m'\u001b[39m\u001b[39mSimilarity Score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df3\u001b[39m.\u001b[39mapply(word_vector_similarity, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df1[\u001b[39m'\u001b[39m\u001b[39mSentiment score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df1\u001b[39m.\u001b[39;49mapply(sentiment_analysis, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df2[\u001b[39m'\u001b[39m\u001b[39mSentiment score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df2\u001b[39m.\u001b[39mapply(sentiment_analysis, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df3[\u001b[39m'\u001b[39m\u001b[39mSentiment score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df3\u001b[39m.\u001b[39mapply(sentiment_analysis, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9422\u001b[0m )\n\u001b[1;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\rahul\\OneDrive\\Documents\\Fall\\Unstructured data analytics\\Assignment 2\\beer-recommender-system\\assignment-sanj-rach.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msentiment_analysis\u001b[39m(df):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     sentiment\u001b[39m=\u001b[39m sentiment_pipeline(df[\u001b[39m'\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m sentiment[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPOSITIVE\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rahul/OneDrive/Documents/Fall/Unstructured%20data%20analytics/Assignment%202/beer-recommender-system/assignment-sanj-rach.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m sentiment[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    123\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    157\u001b[0m     \u001b[39m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     _legacy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtop_k\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[0;32m   1133\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[0;32m   1134\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         )\n\u001b[0;32m   1138\u001b[0m     )\n\u001b[0;32m   1139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1146\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1147\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[0;32m   1148\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1149\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1045\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1046\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[0;32m   1047\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1048\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(model_forward)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    186\u001b[0m     model_inputs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs)\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:789\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    787\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m--> 789\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistilbert(\n\u001b[0;32m    790\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m    791\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    792\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m    793\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m    794\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    795\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m    796\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m    797\u001b[0m )\n\u001b[0;32m    798\u001b[0m hidden_state \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    799\u001b[0m pooled_output \u001b[39m=\u001b[39m hidden_state[:, \u001b[39m0\u001b[39m]  \u001b[39m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:607\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    605\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 607\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(\n\u001b[0;32m    610\u001b[0m     x\u001b[39m=\u001b[39membeddings,\n\u001b[0;32m    611\u001b[0m     attn_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    615\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m    616\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:135\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[1;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[0;32m    131\u001b[0m     position_ids \u001b[39m=\u001b[39m position_ids\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mexpand_as(input_ids)  \u001b[39m# (bs, max_seq_length)\u001b[39;00m\n\u001b[0;32m    133\u001b[0m position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m embeddings \u001b[39m=\u001b[39m input_embeds \u001b[39m+\u001b[39;49m position_embeddings  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    137\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (580) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "df1['Similarity Score'] = df1.apply(word_vector_similarity, axis=1)\n",
    "df2['Similarity Score'] = df2.apply(word_vector_similarity, axis=1)\n",
    "df3['Similarity Score'] = df3.apply(word_vector_similarity, axis=1)\n",
    "\n",
    "df1['Sentiment score'] = df1.apply(sentiment_analysis, axis=1)\n",
    "df2['Sentiment score'] = df2.apply(sentiment_analysis, axis=1)\n",
    "df3['Sentiment score'] = df3.apply(sentiment_analysis, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>body</th>\n",
       "      <th>rating</th>\n",
       "      <th>Customer attribute</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>amazing stout expensive worth price</td>\n",
       "      <td>5.00</td>\n",
       "      <td>robust</td>\n",
       "      <td>0.486838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>beer meet exceeded unreal hype simply amazing</td>\n",
       "      <td>5.00</td>\n",
       "      <td>robust</td>\n",
       "      <td>0.410720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>let sit warm room little unbelievable</td>\n",
       "      <td>5.00</td>\n",
       "      <td>robust</td>\n",
       "      <td>0.285641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>small pour ebony dark real head intense rich a...</td>\n",
       "      <td>4.67</td>\n",
       "      <td>robust</td>\n",
       "      <td>0.445239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>vintage 2022 served tap toppling goliath snuli...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>robust</td>\n",
       "      <td>0.492351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          item  \\\n",
       "0  Kentucky Brunch Brand Stout   \n",
       "1  Kentucky Brunch Brand Stout   \n",
       "2  Kentucky Brunch Brand Stout   \n",
       "3  Kentucky Brunch Brand Stout   \n",
       "4  Kentucky Brunch Brand Stout   \n",
       "\n",
       "                                                body  rating  \\\n",
       "0                amazing stout expensive worth price    5.00   \n",
       "1      beer meet exceeded unreal hype simply amazing    5.00   \n",
       "2              let sit warm room little unbelievable    5.00   \n",
       "3  small pour ebony dark real head intense rich a...    4.67   \n",
       "4  vintage 2022 served tap toppling goliath snuli...    5.00   \n",
       "\n",
       "  Customer attribute  Similarity Score  \n",
       "0             robust          0.486838  \n",
       "1             robust          0.410720  \n",
       "2             robust          0.285641  \n",
       "3             robust          0.445239  \n",
       "4             robust          0.492351  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Overall score']= df['Similarity score']*df['Sentiment score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task H\n",
    "Using the top four attributes of beer (from word frequency analysis), calculate the lifts between\n",
    "these attributes and any 10 beers in your data. Choose one beer, and find the most similar beer (among\n",
    "the remaining 9) using the lift values. Explain your method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(list1, list2):\n",
    "    attribute_mentions_per_review = {attribute: set() for attribute in list1 + list2}\n",
    "    co_mentions = {}\n",
    "    for attr1 in list1 + list2:\n",
    "        co_mentions[attr1] = {}\n",
    "        for brand in list1 + list2:\n",
    "            co_mentions[attr1][brand] = 0\n",
    "    individual_mentions = {attr: 0 for attr in list1 + list2}\n",
    "    lift_ratios = {}\n",
    "    lift_already_calculated = set()\n",
    "    return co_mentions, attribute_mentions_per_review, individual_mentions, lift_ratios, lift_already_calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lift(attr1, brand, co_mentions, individual_mentions, total_posts):\n",
    "    if attr1 == brand:\n",
    "        return 0  # Lift ratio between the same brand is 0\n",
    "    # Calculate lift using the formula: lift(attr1, brand) = (P(attr1 and brand) / (P(attr1) * P(brand))) * N\n",
    "    p_attr1_and_brand = co_mentions[attr1][brand]\n",
    "    p_attr1 = individual_mentions[attr1]\n",
    "    p_brand = individual_mentions[brand]\n",
    "    if p_attr1 == 0 or p_brand == 0:\n",
    "        return 0  \n",
    "    else:\n",
    "        return (p_attr1_and_brand / (p_attr1 * p_brand)) * total_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweet',\n",
       " 'carbonation',\n",
       " 'mouthfeel',\n",
       " 'smooth',\n",
       " 'caramel',\n",
       " 'clear',\n",
       " 'sweetness',\n",
       " 'dry',\n",
       " 'bitter',\n",
       " 'malty']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selected_beer_brands=[\"Mornin' Delight\",\"Nelson\",\"Stickee Monkee\",\"The Wild One\",\"Corsendonk Christmas Ale\"]\n",
    "selected_beer_brands=[\"Old Chub\",\"Voodoo Ranger Juicy Haze IPA\",\"Harvest Ale (Limited Edition)\",\"The Angel's Share - Bourbon Barrel-Aged\",\"Weihenstephaner Korbinian\",\"G'Knight\",\"Mirror Pond Pale Ale\",\"Antarctica Pilsen\",\"Dark Lord\",\"Breakfast Stout\"]\n",
    "attributes=list(attr_word_freq['word'])[:10]\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_df = pd.DataFrame(index=attributes, columns=selected_beer_brands)\n",
    "for brand in selected_beer_brands:\n",
    "    for attr in attributes:\n",
    "        # Calculate support and joint support\n",
    "        df['body'].fillna('', inplace=True)\n",
    "        support_attr = len(df[df['body'].str.contains(attr)]) / len(df)\n",
    "        support_brand = len(df[df['item'] == brand]) / len(df)\n",
    "        joint_support = len(df[(df['body'].str.contains(attr)) & (df['item'] == brand)]) / len(df)\n",
    "        \n",
    "        # Calculate lift\n",
    "        if support_attr * support_brand == 0:\n",
    "            lift = 0  # Avoid division by zero\n",
    "        else:\n",
    "            lift = joint_support / (support_attr * support_brand)\n",
    "\n",
    "        lift_df.at[attr, brand] = lift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Old Chub</th>\n",
       "      <th>Voodoo Ranger Juicy Haze IPA</th>\n",
       "      <th>Harvest Ale (Limited Edition)</th>\n",
       "      <th>The Angel's Share - Bourbon Barrel-Aged</th>\n",
       "      <th>Weihenstephaner Korbinian</th>\n",
       "      <th>G'Knight</th>\n",
       "      <th>Mirror Pond Pale Ale</th>\n",
       "      <th>Antarctica Pilsen</th>\n",
       "      <th>Dark Lord</th>\n",
       "      <th>Breakfast Stout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sweet</th>\n",
       "      <td>2.692776</td>\n",
       "      <td>0.349064</td>\n",
       "      <td>2.094381</td>\n",
       "      <td>1.178089</td>\n",
       "      <td>1.713585</td>\n",
       "      <td>1.570786</td>\n",
       "      <td>0.523595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.24398</td>\n",
       "      <td>1.256629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carbonation</th>\n",
       "      <td>0.576906</td>\n",
       "      <td>0.448705</td>\n",
       "      <td>1.682644</td>\n",
       "      <td>1.009586</td>\n",
       "      <td>1.468489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.346115</td>\n",
       "      <td>2.019172</td>\n",
       "      <td>1.730719</td>\n",
       "      <td>0.807669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouthfeel</th>\n",
       "      <td>0.841791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.473135</td>\n",
       "      <td>2.209702</td>\n",
       "      <td>1.071371</td>\n",
       "      <td>2.209702</td>\n",
       "      <td>0.98209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.683583</td>\n",
       "      <td>0.589254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smooth</th>\n",
       "      <td>0.979191</td>\n",
       "      <td>0.761593</td>\n",
       "      <td>2.28478</td>\n",
       "      <td>2.570377</td>\n",
       "      <td>0.623122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.14239</td>\n",
       "      <td>1.14239</td>\n",
       "      <td>0.979191</td>\n",
       "      <td>2.056302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caramel</th>\n",
       "      <td>3.88466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.776753</td>\n",
       "      <td>5.66513</td>\n",
       "      <td>4.120094</td>\n",
       "      <td>2.266052</td>\n",
       "      <td>1.510701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clear</th>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874868</td>\n",
       "      <td>2.332982</td>\n",
       "      <td>3.499473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sweetness</th>\n",
       "      <td>1.305588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.046373</td>\n",
       "      <td>1.14239</td>\n",
       "      <td>0.830829</td>\n",
       "      <td>3.427169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.305588</td>\n",
       "      <td>2.741736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dry</th>\n",
       "      <td>1.063813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620557</td>\n",
       "      <td>0.930836</td>\n",
       "      <td>0.676972</td>\n",
       "      <td>0.930836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitter</th>\n",
       "      <td>0.619514</td>\n",
       "      <td>0.481845</td>\n",
       "      <td>0.722767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.788473</td>\n",
       "      <td>1.08415</td>\n",
       "      <td>0.722767</td>\n",
       "      <td>0.722767</td>\n",
       "      <td>0.619514</td>\n",
       "      <td>2.601961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>malty</th>\n",
       "      <td>5.564719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.082029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.36079</td>\n",
       "      <td>3.246086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Old Chub Voodoo Ranger Juicy Haze IPA  \\\n",
       "sweet        2.692776                     0.349064   \n",
       "carbonation  0.576906                     0.448705   \n",
       "mouthfeel    0.841791                          0.0   \n",
       "smooth       0.979191                     0.761593   \n",
       "caramel       3.88466                          0.0   \n",
       "clear        0.999849                          0.0   \n",
       "sweetness    1.305588                          0.0   \n",
       "dry          1.063813                          0.0   \n",
       "bitter       0.619514                     0.481845   \n",
       "malty        5.564719                          0.0   \n",
       "\n",
       "            Harvest Ale (Limited Edition)  \\\n",
       "sweet                            2.094381   \n",
       "carbonation                      1.682644   \n",
       "mouthfeel                        1.473135   \n",
       "smooth                            2.28478   \n",
       "caramel                          3.776753   \n",
       "clear                                 0.0   \n",
       "sweetness                        3.046373   \n",
       "dry                              0.620557   \n",
       "bitter                           0.722767   \n",
       "malty                            1.082029   \n",
       "\n",
       "            The Angel's Share - Bourbon Barrel-Aged Weihenstephaner Korbinian  \\\n",
       "sweet                                      1.178089                  1.713585   \n",
       "carbonation                                1.009586                  1.468489   \n",
       "mouthfeel                                  2.209702                  1.071371   \n",
       "smooth                                     2.570377                  0.623122   \n",
       "caramel                                     5.66513                  4.120094   \n",
       "clear                                           0.0                       0.0   \n",
       "sweetness                                   1.14239                  0.830829   \n",
       "dry                                        0.930836                  0.676972   \n",
       "bitter                                          0.0                  0.788473   \n",
       "malty                                           0.0                   2.36079   \n",
       "\n",
       "             G'Knight Mirror Pond Pale Ale Antarctica Pilsen Dark Lord  \\\n",
       "sweet        1.570786             0.523595               0.0   2.24398   \n",
       "carbonation       0.0             1.346115          2.019172  1.730719   \n",
       "mouthfeel    2.209702              0.98209               0.0  1.683583   \n",
       "smooth            0.0              1.14239           1.14239  0.979191   \n",
       "caramel      2.266052             1.510701               0.0       0.0   \n",
       "clear        0.874868             2.332982          3.499473       0.0   \n",
       "sweetness    3.427169                  0.0               0.0  1.305588   \n",
       "dry          0.930836                  0.0               0.0       0.0   \n",
       "bitter        1.08415             0.722767          0.722767  0.619514   \n",
       "malty        3.246086                  0.0               0.0       0.0   \n",
       "\n",
       "            Breakfast Stout  \n",
       "sweet              1.256629  \n",
       "carbonation        0.807669  \n",
       "mouthfeel          0.589254  \n",
       "smooth             2.056302  \n",
       "caramel                 0.0  \n",
       "clear                   0.0  \n",
       "sweetness          2.741736  \n",
       "dry                0.744669  \n",
       "bitter             2.601961  \n",
       "malty                   0.0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar beer to Weihenstephaner Korbinian is The Angel's Share - Bourbon Barrel-Aged based on the attribute 'caramel' with a lift value of 5.665129781420765.\n"
     ]
    }
   ],
   "source": [
    "# Choose a reference beer (replace with the beer you want to use as reference)\n",
    "reference_beer = 'Weihenstephaner Korbinian'\n",
    "\n",
    "# Create a dictionary to store the most similar beer for each reference attribute\n",
    "most_similar_beers = {}\n",
    "\n",
    "# Iterate through the remaining nine beers\n",
    "for beer in selected_beer_brands:\n",
    "    if beer != reference_beer:  # Exclude the reference beer itself\n",
    "        most_similar_attribute = None\n",
    "        highest_lift = 0.0\n",
    "\n",
    "        # Find the attribute with the highest lift value when associated with the reference beer\n",
    "        for attribute in attributes:\n",
    "            lift_value = lift_df.at[attribute, beer]\n",
    "            if lift_value > highest_lift:\n",
    "                highest_lift = lift_value\n",
    "                most_similar_attribute = attribute\n",
    "\n",
    "        # Store the most similar beer for the reference beer\n",
    "        most_similar_beers[beer] = (most_similar_attribute, highest_lift)\n",
    "\n",
    "# Find the beer with the highest lift value\n",
    "most_similar_beer = max(most_similar_beers, key=lambda x: most_similar_beers[x][1])\n",
    "similar_attribute, highest_lift = most_similar_beers[most_similar_beer]\n",
    "\n",
    "print(f\"The most similar beer to {reference_beer} is {most_similar_beer} based on the attribute '{similar_attribute}' with a lift value of {highest_lift}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
